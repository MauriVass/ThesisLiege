{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandapower as pp\n",
    "import pandapower.networks\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "np.random.seed(14)\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pandapower.plotting.plotly import simple_plotly\n",
    "from pandapower.plotting.plotly import vlevel_plotly\n",
    "from pandapower.plotting.plotly import pf_res_plotly\n",
    "\n",
    "from pandapower.timeseries import DFData\n",
    "from pandapower.timeseries import OutputWriter\n",
    "from pandapower.timeseries.run_time_series import run_timeseries\n",
    "from pandapower.control import ConstControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = pp.networks.mv_oberrhein()\n",
    "net1, net2 = pp.networks.mv_oberrhein(separation_by_sub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number buses: {len(net.bus)}')\n",
    "print(f'Number loads: {len(net.load)}')\n",
    "print(f'Number sgens: {len(net.sgen)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [int(i.split(' ')[-1]) for i in net.bus['name']]\n",
    "bus_indices = net.bus.index\n",
    "\n",
    "c = {}\n",
    "l = 0 \n",
    "s = 0\n",
    "for i in bus_indices:\n",
    "\tc[i] = [0,0]\n",
    "\tif(i in list(net.load['bus'])):\n",
    "\t\tc[i][0]+=1\n",
    "\t\tl+=1\n",
    "\tif(i in list(net.sgen['bus'])):\n",
    "\t\tc[i][1]+=1\n",
    "\t\ts+=1\n",
    "print('{bus index, [load,gen]}')\n",
    "print(c)\n",
    "\n",
    "l = [[],[],[],[]]\n",
    "for k,v in c.items():\n",
    "\tif(v[0]==0 and v[1]==0): #nothing\n",
    "\t\tl[0].append(k) \n",
    "\tif(v[0]>0 and v[1]==0): #only load\n",
    "\t\tl[1].append(k)\n",
    "\tif(v[0]==0 and v[1]>0): #only sgen\n",
    "\t\tl[2].append(k)\n",
    "\tif(v[0]>0 and v[1]>0): #both\n",
    "\t\tl[3].append(k)\n",
    "print('\\nNothing: ', l[0])\n",
    "print('Only load: ', l[1])\n",
    "print('Only sgen: ', l[2])\n",
    "print('Both: ', l[3])\n",
    "print(f'Ratio: Nothing/at least 1: {( len(l[0])/( len(l[0])+len(l[1])+len(l[2])+len(l[3]) ) ):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [int(i.split(' ')[-1]) for i in net.bus['name']]\n",
    "bus_indices = net.bus.index\n",
    "\n",
    "c = []\n",
    "nc = []\n",
    "l = 0\n",
    "for i in net.load.to_numpy():\n",
    "\tif(i[1] in bus_indices):\n",
    "\t\tc.append(i[1])\n",
    "\t\tl+=1\n",
    "\telse:\n",
    "\t\tnc.append(i[1])\n",
    "print(f'Loads connected to something: {c}')\n",
    "print(f'Loads connected to nothing: {nc}')\n",
    "\n",
    "print(f'\\nLoads-> total: {len(net.load)}, connected to some bus: {l} (ratio: {(l/len(net.load)):.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [int(i.split(' ')[-1]) for i in net.bus['name']]\n",
    "bus_indices = net.bus.index\n",
    "\n",
    "c = []\n",
    "nc = []\n",
    "l = 0\n",
    "for i in net.sgen.to_numpy():\n",
    "\tif(i[1] in bus_indices):\n",
    "\t\tc.append(i[1])\n",
    "\t\tl+=1\n",
    "\telse:\n",
    "\t\tnc.append(i[1])\n",
    "print(f'Sgens connected to something: {c}')\n",
    "print(f'Sgens connected to nothing: {nc}')\n",
    "\n",
    "print(f'\\nSgens-> total: {len(net.sgen)}, connected to some bus: {l} (ratio: {(l/len(net.sgen)):.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.load[net.load['scaling'] == 0].count())\n",
    "print(net.sgen[net.sgen['scaling'] == 0].count()) #All sgen scaling value set to 0!!!! I was wandering why changing sgens time series didn't bring to different results -.-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the scaling values are 0.6\n",
    "# net.load['scaling'] = 0.6\n",
    "net.sgen['scaling'] = 0.6\n",
    "#Can be changed also in the Controllers\n",
    "\n",
    "net.sgen['sn_mva'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_foreach_element(arr):\n",
    "\td = {}\n",
    "\tfor i in arr.to_numpy():\n",
    "\t\ti = i[0]\n",
    "\t\td[i] = d[i]+1 if i in d.keys() else 1\n",
    "\treturn d\n",
    "\t\n",
    "input_dir = './TimeSeries/1-MVLV-rural-all-0-sw/'\n",
    "n_timesteps = 4 * 24 * 20\n",
    "\n",
    "#Loads dataset\n",
    "profile_load = pd.DataFrame()\n",
    "n_load = len(net.load)\n",
    "n_res = len(net.sgen)\n",
    "# The parameter “sR” generally describes the nominal apparent power of power plants, distributed energy resources and loads\n",
    "loads = pd.read_csv(f'{input_dir}Load.csv', sep=';')\n",
    "loads_timeseries = pd.read_csv(f'{input_dir}LoadProfile.csv', sep=';')\n",
    "\n",
    "RESs = pd.read_csv(f'{input_dir}RES.csv', sep=';')\n",
    "RESs_timeseries = pd.read_csv(f'{input_dir}RESProfile.csv', sep=';')\n",
    "\n",
    "#Cases:\n",
    "# 0: low load, high generation\n",
    "# 1: normal load and generation\n",
    "# 2: high load, low generation\n",
    "case = 0\n",
    "if(case==-1):\n",
    "\tscale_factor_load = 1.1\n",
    "\tscale_factor_sgen = 2.5\n",
    "if(case==0):\n",
    "\tscale_factor_load = 0.7\n",
    "\tscale_factor_sgen = 1.4\n",
    "elif(case==1):\n",
    "\tscale_factor_load = 1\n",
    "\tscale_factor_sgen = 1\n",
    "elif(case==2):\n",
    "\tscale_factor_load = round(0.8/0.6)\n",
    "\tscale_factor_sgen = 0.1\n",
    "print(f'Case: {case}, scale load: {scale_factor_load}, scale sgen: {scale_factor_sgen}')\n",
    "'''\n",
    "# Papers:\n",
    "# SimBench—A Benchmark Dataset of Electric Power Systems to Compare Innovative Solutions Based on Power Flow Analysis\n",
    "# https://www.researchgate.net/profile/Christian-Spalthoff-2/publication/333903713_SimBench_Open_source_time_series_of_power_load_storage_and_generation_for_the_simulation_of_electrical_distribution_grids/links/5d889953458515cbd1b50cef/SimBench-Open-source-time-series-of-power-load-storage-and-generation-for-the-simulation-of-electrical-distribution-grids.pdf?origin=publication_detail\n",
    "# https://publica.fraunhofer.de/eprints/urn_nbn_de_0011-n-5554297.pdf\n",
    "Germany standard load profiles(SLPs): Commercial enterprises (G), households (H), agricultural holdings (L) and industrial companies\n",
    "(BL/BW) were considered as accumulated consumers, while the provided time series for electric\n",
    "vehicles (EVs) and heat pumps (HPs) were interpreted as individual consumers.\n",
    "Ending letter: A-C low consumption, M medium, H high\n",
    "#print(set(loads_timeseries.columns)) \n",
    "'''\n",
    "# net.controller = pd.DataFrame() #Reset controllers\n",
    "# index_to_select = range(n_load) #np.random.randint(0,len(loads),size=n_load)\n",
    "index_to_select = np.random.randint(0,len(loads),size=n_load)\n",
    "loads_type = loads.loc[index_to_select,['profile']]\n",
    "temp_profile_p = []\n",
    "temp_profile_q = []\n",
    "print(f'Chosen load elements by type: {num_foreach_element(loads_type)}')\n",
    "for l in loads_type.to_numpy():\n",
    "\tval = 0\n",
    "\tnoise = np.random.uniform(1-val,1+val,len(loads_timeseries)) #random noise in range [1-val,1+val[ -> change timeseries values by +/-val%\n",
    "\ttemp_profile_q.append( loads_timeseries[f'{l[0]}_qload']*noise )\n",
    "\ttemp_profile_p.append( loads_timeseries[f'{l[0]}_pload']*noise*0.3 )\n",
    "\n",
    "#Loads p (in MW) \n",
    "profile_load_p = pd.concat(temp_profile_p,axis=1)[:n_timesteps]\n",
    "profile_load_p.columns = net.load.index\n",
    "ds_lp = DFData(profile_load_p)\n",
    "cc_lp = ConstControl(net, 'load', 'p_mw', element_index=net.load.index, profile_name=profile_load_p.columns,\n",
    "\t\t\t\t\tdata_source=ds_lp, scale_factor=scale_factor_load)\n",
    "\n",
    "#Loads q (in MVar)\n",
    "profile_load_q = pd.concat(temp_profile_q,axis=1)[:n_timesteps]\n",
    "profile_load_q.columns = net.load.index\n",
    "ds_lq = DFData(profile_load_q)\n",
    "cc_lq = ConstControl(net, 'load', 'q_mvar', element_index=net.load.index, profile_name=profile_load_q.columns,\n",
    "\t\t\t\t\tdata_source=ds_lq, scale_factor=scale_factor_load)\n",
    "\n",
    "#RES p (in MW)\n",
    "res_to_add = pd.DataFrame(['WP4','WP7','WP4','WP7','WP4','WP7'], columns=['profile'])\n",
    "RESs_type = RESs.loc[:n_res-1-len(res_to_add),['profile']]\n",
    "RESs_type = pd.concat([RESs_type, res_to_add])\n",
    "temp_profile_p = []\n",
    "print(f'RES elements by type: {num_foreach_element(RESs_type)}')\n",
    "for l in RESs_type.to_numpy():\n",
    "\tval = .25\n",
    "\tnoise = np.random.uniform(1-val,1+val,len(loads_timeseries)) #random noise in range [1-val,1+val[ -> change timeseries values by +/-val%\n",
    "\ttemp_profile_p.append(RESs_timeseries[f'{l[0]}']*noise)\n",
    "\t# temp_profile_p.append(RESs_timeseries[f'{l[0]}_pload']) #Q values are not required\n",
    "\n",
    "profile_res_p = pd.concat(temp_profile_p,axis=1)[:n_timesteps]\n",
    "profile_res_p.columns = net.sgen.index\n",
    "ds_sp = DFData(profile_res_p)\n",
    "cc_sp = ConstControl(net, 'sgen', 'p_mw', element_index=net.sgen.index, profile_name=profile_res_p.columns,\n",
    "\t\t\t\t\tdata_source=ds_sp, scale_factor=scale_factor_sgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(20, 3)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "(cc_lp.data_source.df*cc_lp.scale_factor).sum(axis=1).plot(label='load p',ylabel='mw')\n",
    "(cc_lq.data_source.df*cc_lq.scale_factor).sum(axis=1).plot(label='load q',ylabel='mw')\n",
    "(cc_sp.data_source.df*cc_sp.scale_factor).sum(axis=1).plot(label='sgen')\n",
    "# profile_res_p.loc[:,['PV5', 'PV8', 'PV6']].sum(axis=1).plot(label='sgen PV')\n",
    "# profile_res_p.loc[:,['WP4','WP7']].sum(axis=1).plot(label='sgen WP')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = profile_load_p\n",
    "# df =  df.loc[:,~df.columns.duplicated()]\n",
    "df.boxplot(rot=45,figsize=figsize)\n",
    "plt.ylabel('mw (?)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = range(0,n_timesteps)\n",
    "\n",
    "output_dir = os.path.join(input_dir,\"Results\", str(case))\n",
    "ow = OutputWriter(net, time_steps, output_path=output_dir, output_file_type=\".csv\", log_variables=list())\n",
    "\n",
    "#Save time series (output)\n",
    "# these variables are saved to the harddisk after / during the time series loop\n",
    "ow.log_variable('res_load', 'p_mw')\n",
    "ow.log_variable('res_load', 'q_mvar')\n",
    "ow.log_variable('res_bus', 'vm_pu')\n",
    "# ow.log_variable('res_bus', 'va_degree')\n",
    "ow.log_variable('res_line', 'loading_percent')\n",
    "# ow.log_variable('res_line', 'i_ka')\n",
    "\n",
    "print('Time steps: ',len(time_steps), '. Num Loads: ', net.load.index.shape, '. Load p and q: ', profile_load_p.shape, profile_load_q.shape, '. Num RESs: ', net.sgen.index.shape, '. RESs p: ',profile_res_p.shape)\n",
    "t1 = time.time()\n",
    "run_timeseries(net,time_steps)\n",
    "t2 = time.time()\n",
    "print(f'Simulation time : {(t2-t1):.2f} s')\n",
    "\n",
    "#Save time series (input)\n",
    "path = os.path.join(output_dir, \"loads_p.csv\")\n",
    "(cc_lp.data_source.df*cc_lp.scale_factor).to_csv(path)\n",
    "path = os.path.join(output_dir, \"loads_q.csv\")\n",
    "(cc_lq.data_source.df*cc_lq.scale_factor).to_csv(path)\n",
    "path = os.path.join(output_dir, \"RESs_p.csv\")\n",
    "(cc_sp.data_source.df*cc_sp.scale_factor).to_csv(path)\n",
    "t3 = time.time()\n",
    "print(f'Saving files time: {(t3-t2):.2f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1000\n",
    "fig = px.line(cc_lp.data_source.df*cc_lp.scale_factor,x=time_steps, y=profile_load_p.columns, width=width, height=400)\n",
    "fig.show()\n",
    "fig = px.line(cc_lq.data_source.df*cc_lq.scale_factor,x=time_steps, y=profile_load_q.columns, width=width, height=400)\n",
    "fig.show()\n",
    "fig = px.line(cc_sp.data_source.df*cc_sp.scale_factor,x=time_steps, y=profile_res_p.columns, width=width, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df,title='',y_axis='',file_name=''):\n",
    "\tfig = px.line(df,x=time_steps, y=df.columns, width=1200, height=800)\n",
    "\tfig.update_layout(title=title,\n",
    "\t\t\t\t\txaxis_title='time steps',\n",
    "\t\t\t\t\tyaxis_title=y_axis)\n",
    "\tif(file_name):\n",
    "\t\tfig.write_html(file_name)\n",
    "\t\tprint(f'Saved {title} in {file_name}')\n",
    "\n",
    "output_dir = os.path.join(input_dir,\"Results\", str(case))\n",
    "\n",
    "# voltage results\n",
    "vm_pu_file = os.path.join(output_dir, \"res_bus\", \"vm_pu.csv\")\n",
    "vm_pu = pd.read_csv(vm_pu_file, index_col=0, sep=';')\n",
    "vm_pu = vm_pu.drop(columns='58' ) #External grid\n",
    "# plot_df(vm_pu,'buses voltage magnitude', 'bus vm [pu]', os.path.join(output_dir, \"Plots\", \"bus vm.html\"))\n",
    "\n",
    "# # line loading resulcsvts\n",
    "ll_file = os.path.join(output_dir, \"res_line\", \"loading_percent.csv\")\n",
    "line_loading = pd.read_csv(ll_file, index_col=0, sep=';')\n",
    "# plot_df(line_loading,'line_loading', 'line_loading [%]', os.path.join(output_dir, \"Plots\", \"line load.html\"))\n",
    "\n",
    "# # load results\n",
    "load_file = os.path.join(output_dir, \"res_load\", \"p_mw.csv\")\n",
    "load = pd.read_csv(load_file, index_col=0, sep=';')\n",
    "# plot_df(load,'load active power', 'p [MW]', os.path.join(output_dir, \"Plots\", \"load.html\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['max'] = vm_pu.max(axis=1)\n",
    "df['min'] = vm_pu.min(axis=1)\n",
    "ch = []\n",
    "cl = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\tif(row['max']>1.05):\n",
    "\t\tch.append('r')\n",
    "\telse:\n",
    "\t\tch.append('b')\n",
    "\tif(row['min']<0.95):\n",
    "\t\tcl.append('r')\n",
    "\telse:\n",
    "\t\tcl.append('b')\n",
    "\t\t\n",
    "df['over'] = ch\n",
    "df['under'] = cl\n",
    "# # d = {True: 'Voltage problem', False: 'Normal condition'}\n",
    "# # df = df.replace(d)\n",
    "# fig = px.scatter(df,x=df.index,y='max',color='over', width=1000, height=400)\n",
    "# # fig.update_yaxes(type='category')\n",
    "# fig.update_traces(marker_size=5)\n",
    "# fig.update_layout(\n",
    "# \ttitle=\"\",\n",
    "# \txaxis_title=\"Time steps\",\n",
    "# \tyaxis_title=\"max bus vm [pu]\",\n",
    "# \tlegend_title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,5))\n",
    "s = 27\n",
    "ma = plt.scatter(x=df.index,y=df['max'],c=df['over'],s=s, marker='^')\n",
    "mi = plt.scatter(x=df.index,y=df['min'],c=df['under'],s=s, marker='v')\n",
    "\n",
    "plt.scatter(x=[],y=[],c=['r'], marker='^', s=s, label='Maxs overvoltages')\n",
    "plt.scatter(x=[],y=[],c=['b'], marker='^', s=s, label='Maxs normal')\n",
    "plt.scatter(x=[],y=[],c=['r'], marker='v', s=s, label='Mins undervoltages')\n",
    "plt.scatter(x=[],y=[],c=['b'], marker='v', s=s, label='Mins normal')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot network and loadings\n",
    "\n",
    "bus = 58\n",
    "fig = simple_plotly(net, bus_size=5, ext_grid_size=10)\n",
    "fig.add_trace(px.scatter(x=[net.bus_geodata.loc[bus, 'x']], y=[net.bus_geodata.loc[bus, 'y']],color=['r'],size=[10]).data[0])\n",
    "# _ = vlevel_plotly(net, bus_size=5, ext_grid_size=10)\n",
    "# fig = pf_res_plotly(net, bus_size=8)\n",
    "# fig.write_html(f\"images/MVOberrhein/Half2.html\")\n",
    "# fig.write_image(f\"images/MVOberrhein/Half2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vm_pu[58]) #constant voltage?\n",
    "print(net.bus.loc[95])\n",
    "print(net.load[net.load['bus']==58]) #no load in bus 58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vm_pu.plot(label=\"vm_pu\", figsize=figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive version\n",
    "def classification_dataset(df):\n",
    "\tlabels = []\n",
    "\ta = 0\n",
    "\tacceptance_range = 0.1\n",
    "\tfor i in df.to_numpy():\n",
    "\t\tif(np.any(i>1+acceptance_range/2) or np.any(i<1-acceptance_range/2) ):#or np.any(i<1-acceptance_range/2)\n",
    "\t\t\tlabels.append(1)\n",
    "\t\t\ta+=1\n",
    "\t\telse:\n",
    "\t\t\tlabels.append(0)\n",
    "\tprint(f'Number of problems: {a}, total number: {len(df)}, ratio: {(a/len(df)*100):.1f}%')\n",
    "\treturn pd.DataFrame(labels,columns=['Label'])\n",
    "\n",
    "vm_pu_classification = classification_dataset(vm_pu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load\n",
    "y = vm_pu_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.columns = [f'l_{name}' for name in x.columns]\n",
    "# y.columns = [f'bvm_{name}' for name in y.columns]\n",
    "df = pd.concat([x], axis=1)\n",
    "\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.7)]\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\n",
    "test_df = df[int(n*0.9):]\n",
    "\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "if(True):\n",
    "\ttrain_df = pd.concat( [(train_df - train_mean) / train_std,y[0:int(n*0.7)]], axis=1)\n",
    "\tval_df = pd.concat( [(val_df - train_mean) / train_std,y[int(n*0.7):int(n*0.9)]], axis=1)\n",
    "\ttest_df = pd.concat( [(test_df - train_mean) / train_std,y[int(n*0.9):]], axis=1)\n",
    "else:\n",
    "\ttrain_df = pd.concat( [(train_df), y[0:int(n*0.7)]], axis=1)\n",
    "\tval_df = pd.concat( [(val_df), y[int(n*0.7):int(n*0.9)]], axis=1)\n",
    "\ttest_df = pd.concat( [(test_df), y[int(n*0.9):]], axis=1)\n",
    "\n",
    "print(train_df.shape,val_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y[int(n*0.9):]\n",
    "print(a.sum(),a.sum()/a.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "\tdef __init__(self, input_width, label_width, shift,\n",
    "\t\t\t\ttrain_df=train_df, val_df=val_df, test_df=test_df,\n",
    "\t\t\t\tall_columns =None, training_columns=None, label_columns=None):\n",
    "\t\t# Store the raw data.\n",
    "\t\tself.train_df = train_df\n",
    "\t\tself.val_df = val_df\n",
    "\t\tself.test_df = test_df\n",
    "\n",
    "\t\tself.all_columns = all_columns\n",
    "\t\tself.column_indices = {name: i for i, name in enumerate(self.all_columns)}\n",
    "\t\tprint('All columns: ', self.column_indices)\n",
    "\n",
    "\t\tself.training_columns = training_columns\n",
    "\t\t# print('Train columns: ', self.column_indices_t)\n",
    "\n",
    "\t\tself.label_columns = label_columns\n",
    "\t\t# print('Label columns: ', self.column_indices_l)\n",
    "\n",
    "\t\t# Work out the window parameters.\n",
    "\t\tself.input_width = input_width\n",
    "\t\tself.label_width = label_width\n",
    "\t\tself.shift = shift\n",
    "\n",
    "\t\tself.total_window_size = input_width + shift\n",
    "\n",
    "\t\tself.input_slice = slice(0, input_width)\n",
    "\t\tself.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "\t\tself.label_start = self.total_window_size - self.label_width\n",
    "\t\tself.labels_slice = slice(self.label_start, None)\n",
    "\t\tself.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "\tdef __repr__(self):\n",
    "\t\treturn '\\n'.join([\n",
    "\t\t\tf'Total window size: {self.total_window_size}',\n",
    "\t\t\tf'Input indices: {self.input_indices}',\n",
    "\t\t\tf'Label indices: {self.label_indices}',\n",
    "\t\t\tf'Label column name(s): {self.label_columns}'])\n",
    "\n",
    "\tdef split_window(self, features):\n",
    "\t\tinputs = features[:, self.input_slice, :]\n",
    "\t\tindices = [self.column_indices[c] for c in self.training_columns]\n",
    "\t\t# inputs = tf.stack( [inputs[:, :, self.all_columns.index(name)] for name in self.training_columns], axis=-1)\n",
    "\t\tinputs = tf.stack( [inputs[:, :, i] for i in indices], axis=-1)\n",
    "\t\tindices = [self.column_indices[c] for c in self.training_columns]\n",
    "\n",
    "\t\t# labels = features[:, self.labels_slice, :]\n",
    "\t\tlabels = features[:, self.labels_slice, :]\n",
    "\t\tindices = [self.column_indices[c] for c in self.label_columns]\n",
    "\n",
    "\t\tlabels = tf.stack( [labels[:, :, i] for i in indices], axis=-1)\n",
    "\t\t# labels = tf.stack( l, axis=-1)\n",
    "\n",
    "\n",
    "\t\t# Slicing doesn't preserve static shape information, so set the shapes\n",
    "\t\t# manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "\t\tinputs.set_shape([None, self.input_width, None])\n",
    "\t\t# labels.set_shape([None, self.label_width, None])\n",
    "\t\tlabels = tf.reshape(labels, [-1,self.label_width])\n",
    "\n",
    "\t\treturn inputs, labels\n",
    "\n",
    "\tdef plot(self, model=None):\n",
    "\t\tpredictions = []\n",
    "\t\tlabels = []\n",
    "\t\ta = 0\n",
    "\t\tfor i,l in self.test:\n",
    "\t\t\tif model is not None:\n",
    "\t\t\t\tpredictions.append(list(tf.reshape(model(i),[-1]).numpy()))\n",
    "\t\t\ta+=1\n",
    "\t\t\tlabels.append(list(tf.reshape(l,[-1]).numpy()))\n",
    "\t\tpredictions = [item for sublist in predictions for item in sublist]\n",
    "\t\tpredictions = np.round(predictions)*0.9 # for visualization purposes\n",
    "\t\tlabels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "\n",
    "\t\tx = range(len(predictions))\n",
    "\t\tplt.figure(figsize=(16,6))\n",
    "\t\ts = 1\n",
    "\t\tplt.scatter(x, predictions,s=s)\n",
    "\t\tplt.scatter(x, labels,s=s)\n",
    "\t\tplt.show()\n",
    "\t\treturn predictions,labels\n",
    "\n",
    "\tdef make_dataset(self, data):\n",
    "\t\tdata = np.array(data, dtype=np.float32)\n",
    "\t\tds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "\t\t\tdata=data,\n",
    "\t\t\ttargets=None,\n",
    "\t\t\tsequence_length=self.total_window_size,\n",
    "\t\t\tsequence_stride=1,\n",
    "\t\t\tshuffle=True,\n",
    "\t\t\tbatch_size=32,)\n",
    "\t\t\t\n",
    "\t\tds = ds.map(self.split_window)\n",
    "\n",
    "\t\treturn ds\n",
    "\n",
    "\t@property\n",
    "\tdef train(self):\n",
    "\t\treturn self.make_dataset(self.train_df)\n",
    "\n",
    "\t@property\n",
    "\tdef val(self):\n",
    "\t\treturn self.make_dataset(self.val_df)\n",
    "\n",
    "\t@property\n",
    "\tdef test(self):\n",
    "\t\treturn self.make_dataset(self.test_df)\n",
    "\n",
    "\t@property\n",
    "\tdef example(self):\n",
    "\t\t\"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "\t\tresult = getattr(self, '_example', None)\n",
    "\t\tif result is None:\n",
    "\t\t\t# No example batch was found, so get one from the `.train` dataset\n",
    "\t\t\tresult = next(iter(self.test))\n",
    "\t\t# And cache it for next time\n",
    "\t\tself._example = result\n",
    "\t\treturn result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = train_df.columns\n",
    "training_columns = x.columns\n",
    "label_columns = y.columns\n",
    "input_window = 2\n",
    "output_window = 1\n",
    "shift = output_window\n",
    "dwg = WindowGenerator(input_window,output_window,shift,all_columns=all_columns,training_columns=training_columns,label_columns=label_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in dwg.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.Sequential([\n",
    "\ttf.keras.layers.Flatten(),\n",
    "\ttf.keras.layers.Dense(units=64*3, activation='relu'),\n",
    "\ttf.keras.layers.Dense(units=64*2, activation='relu'),\n",
    "\ttf.keras.layers.Dense(units=output_window*len(label_columns), activation='sigmoid'),\n",
    "\t# tf.keras.layers.Reshape([output_window, len(label_columns)])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 50\n",
    "\n",
    "monitor = 'val_recall'\n",
    "def compile_and_fit(model, window, patience=6):\n",
    "\tearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=monitor,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tpatience=patience,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tmode='max',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tverbose=1)\n",
    "\n",
    "\tmodel.compile(loss=tf.losses.BinaryCrossentropy(),\n",
    "\t\t\t\toptimizer=tf.optimizers.Adam(),\n",
    "\t\t\t\tmetrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "\t\t\t\t\t\t\ttf.keras.metrics.Precision(name='precision'),\n",
    "\t\t\t\t\t\t\ttf.keras.metrics.Recall(name='recall')]\n",
    "\t\t\t\t)\n",
    "\n",
    "\thistory = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "\t\t\t\t\t\tvalidation_data=window.val,\n",
    "\t\t\t\t\t\tcallbacks=[])#early_stopping\n",
    "\treturn history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(dense, dwg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = np.arange(0,MAX_EPOCHS)\n",
    "# x = np.arange(0,42)\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['loss'], label='Loss'\n",
    ")\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['accuracy'], label='Accuracy'\n",
    ")\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['precision'], label='Precision'\n",
    ")\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['recall'], label='Recall'\n",
    ")\n",
    "plt.title('Evaluation metrics', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_a = np.arange(0,MAX_EPOCHS)\n",
    "# x = np.arange(0,42)\n",
    "# plt.plot(\n",
    "#     x_a,\n",
    "#     history.history['val_loss'], label='Val Loss'\n",
    "# )\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['val_accuracy'], label='Val Accuracy'\n",
    ")\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['val_precision'], label='Val Precision'\n",
    ")\n",
    "plt.plot(\n",
    "    x_a,\n",
    "    history.history['val_recall'], label='Val Recall'\n",
    ")\n",
    "plt.title('Evaluation metrics', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = dwg.plot(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.predict(example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dense.evaluate(dwg.test)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6db62ce4cc779aef3fde0259946866918c32f10b83e429e7a4b776ccea2a2a7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('gyn_anm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
